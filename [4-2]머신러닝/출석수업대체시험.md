# 1장 머신러닝 소개

## 1. 머신러닝의 개념

- 인공지능(강인공지능, 약인공지능) ⊃ 머신러닝 ⊃ 딥러닝
- 인공지능: 인간의 지능을 모방하여 문제해결을 위해 사람처럼 학습하고 이해하는 기계를 만드는 분야
- 머신러닝: 인간이 가지고 있는 고유의 지능적 기능 중 하나인 학습능력을 기계를 통해 구현하는 분야
  - 어떤 문제에 대해 명시적인 지식 표현이나 프로그램을 만드는 것이 어렵거나 불가능한 경우에 주로 사용함
- 딥러닝: 심층 신경망을 이용하여 데이터를 분석하는 학습에 초점을 둔 머신러닝 방법

## 2. 머신러닝의 처리 과정

- 학습 단계와 추론 단계로 구성
- 학습 단계: 주어진 데이터에 대한 분석을 통해 원하는 입·출력의 관계를 알려주는 매핑 함수(결정함수)를 찾는 과정
- 추론 단계: 학습을 통해 찾은 매핑 함수를 새롭게 주어지는 실제 데이터에 적용하여 결과를 얻는 과정

## 3. 머신러닝의 기본 요소

- 하나의 데이터는 n차원의 열벡터 **x** = [*x<sub>1</sub>, x<sub>2</sub>, ... , x<sub>n</sub>*]<sup>T</sup> 로 표현하며, 데이터 처리는 벡터 연산으로 정의됨
- 전체 데이터 집합이 이루는 분포 특성을 고려하여 특징을 추출하고 학습을 수행하는 것이 중요함
- 특징추출: 데이터에서 불필요한 정보를 제거하고 데이터 처리를 위한 핵심적 정보인 특징을 얻는 것
- 학습 시스템: 데이터로부터 학습을 통해 추출하고자 하는 정보를 표현하는 시스템
- 목적함수: 주어진 데이터 집합을 이용하여 학습 시스템이 달성해야 하는 목표를 기계가 알 수 있는 수학적 함수로 정의한 것
- 오차함수: 학습 시스템의 출력과 원하는 출력의 차이(오차)로 정의되는 목적함수
- 성능 평가 기준: 학습오차(학습 데이터 집합을 대상으로 계산된 오차), 테스트 오차(테스트 데이터 집합에 대한 오차), 일반화 오차(관찰될 수 있는 모든 데이터를 대상으로 하는 오차)
- 교차검증법: 제한된 데이터 집합을 이용하여 일반화 오차에 좀 더 근접한 오차값을 얻어 내는 방법

## 4. 머신러닝에서의 주제

- 머신러닝이 다루는 주제: 분류, 회귀, 군집화, 특징추출
- 분류: 입력 데이터가 어떤 부류(클래스)에 속하는지를 자동으로 판단하는 문제
  - 학습 데이터는 입력 데이터와 클래스 레이블의 쌍으로 구성됨
- 회귀: 학습을 통해 입력변수와 원하는 출력변수 사이의 매핑 관계를 분석하고 예측하는 것. 출력은 연속적인 실수값임
- 군집화: 주어지는 클래스 정보 없이 단순히 하나의 덩어리로 이루어진 데이터를 받아서, 데이터의 성질 또는 분포 특성을 분석하여 임의로 복수 개의 그룹으로 나누는 것
- 특징추출: 학습 시스템의 학습 결과로 특정 매핑 함수를 얻게 됨. 새로운 데이터 **x<sub>new</sub>** 는 매핑 함수 f를 통해 특징벡터 **z<sub>new</sub>** 로 변환되어 출력된다.

## 5. 학습 시스템 관련 개념

- 머신러닝의 유형: 지도학습, 비지도학습, 강화학습 등
- 지도학습(교사학습): 학습을 수행할 때 시스템이 출력해야 할 목표 출력값을 함께 제공하는 방식으로, 분류와 회귀 문제에 적합한 유형임
- 비지도학습(비교사학습): 학습할 때 목표 출력값에 대한 정보가 제공되지 않는 방식으로, 군집화 문제에 적합함
- 강화학습: 원하는 출력값을 모르거나 알 수 없는 경우 출력값에 대해 정확한 값의 형태로 교사 신호를 줄 수 없어서 출력값에 대한 교사 신호를 보상 형태로 주는 방식
- 과다적합: 학습 시스템이 학습 데이터에 대해서만 지나치게 적합한 형태로 결정경계를 형성하여 오히려 일반화 성능이 떨어지는 현상

# 4장 지도학습: 분류

## 분류 개념과 관련 용어

- 분류: 주어진 데이터 집합에 대해 이미 정의된 몇 개의 클래스(부류)로 입력을 구분하는 문제
- 분류기(classifier): 분류 문제를 다루는 학습 시스템
- 결정경계: 클래스로의 분류 기준

## 베이즈 분류기와 K-NN 분류기의 기본 개념/동작

- 베이즈 분류기
  - 후험확률에 대한 베이즈 정리로부터 유도된 판별함수 g<sub>i</sub>(**x**) = p(**x**|C<sub>i</sub>)p(C<sub>i</sub>) 를 이용하여 분류하는 방식
  - 새로운 데이터가 주어지면 각 클래스에 대해 g<sub>i</sub>(x)의 값을 계산한 후, 그 값이 가장 큰 클래스로 데이터를 분류함

- K-NN 분류기(K-Nearest Neighbor Classifier)
  - 주어진 데이터로부터 거리가 가까운 순서대로 K개의 데이터를 찾은 후, 그 중 가장 많은 수의 데이터가 속한 클래스로 할당하여 분류하는 방식
  - 분류 과정에서 새로운 데이터가 주어질 때마다 학습 데이터 전체와의 거리 계산을 통해 K개의 이웃 데이터를 선정해 주어야 하므로 항상 학습 데이터를 저장해야 함
    - 데이터의 수가 증가하면 그에 비례하여 계산량과 메모리도 함께 증가하는 문제점

## 이진 분류 문제에서의 베이즈 분류기에서의 결정경계의 형성

- 이진 분류 문제의 전체 데이터 집합ㅇ베서 각 클래스가 차지하는 비율이 p(C<sub>2</sub>)=αp(C<sub>1</sub>) 이라면 p(x|C<sub>2</sub>)=αp(x|C<sub>1</sub>) 를 만족하는 지점이 결정경계가 됨

## 가우시안 베이즈 분류기의 공분산행렬 형태에 따른 판별함수

- 클래스별 확률밀도함수가 가우시안 분포를 따르는 경우에는 공분산행령의 형태(클래스 공통 단위 공분산행렬, 클래스 공통 공분산행렬, 일반적인 공분산행렬)에 따라 결정경계와 판별함수가 달라짐
  - 클래스 공통 단위 공분산행렬: y(x) = argmin<sub>i</sub>{(x-μ<sub>i</sub>)<sup>T</sup>(x-μ<sub>i</sub>)}
  - 클래스 공통 공분산행렬: y(x) = argmin<sub>i</sub>{(x-μ<sub>i</sub>)<sup>T</sup>Σ<sup>-1</sup>(x-μ<sub>i</sub>)}
  - 일반적인 공분산행렬: y(x) = argmin<sub>i</sub>{(x-μ<sub>i</sub>)<sup>T</sup>Σ<sup>-1</sup>(x-μ<sub>i</sub>) + ln|Σ<sub>i</sub>|}

## K-NN 분류기 vs 가우시안 베이즈 분류기

- 베이즈 분류기는 데이터의 확률분포함수를 미리 가정하고 이를 추정하여 분류에 활용
  - 미리 가정한 확률 모델이 주어진 데이터 분포에 적합하지 않으면 좋은 성능을 기대하기 힘들다.
- 이러한 문제에 대한 대안으로 K-NN 분류기를 생각해볼 수 있다.
  - K-NN 분류기는 주어진 데이터로부터 거리가 가까운 순서대로 K개의 데이터를 찾은 후, 그중 가장 많은 수의 데이터가 속한 클래스로 할당하는 방법

## 거리 함수의 종류와 개념

- 2차 노름(유클리디안 거리): 공간상의 두 점을 잇는 직선거리의 길이
- 1차 노름: 각 좌표값의 차이를 모두 더한 값
- p차 노름: p의 값을 조정하여 거리 계산
- 내적: 두 벡터의 방향이 비슷할 수록 그 값이 커진다.(유사한 정도를 파악) 크기에도 영향을 받음
- 코사인 거리: 두 벡터 간의 각도 차이만으로 거리를 평가
- 정규화된 유클리디안 거리, 마할라노비스 거리: 각 좌표축 방향으로의 분산의 차이를 고려하여 반영해 준 거리 함수

## 분류기의 종류

- 베이즈 분류기, K-NN 분류기, 로지스틱 회귀, 결정 트리, SVM, 신경망 등

# 5장 회귀

## 회귀의 개념 및 적용 방법의 종류

- 회귀: 입력을 출력으로 매핑하는 함수를 찾는 문제
  - 입력값, 출력값은 실수
  - 학습 목표는 최적의 회귀함수 f(x:θ) 를 찾는 것
  - 응용 예: 시계열 예측 분야(주가 예측, 시장 예측, 공정 예측 등)
- 적용방법
  - 보간법: 제곱오차가 0, but 얻어지는 곡선이 매우 복잡
  - 회귀: 간단한 직선을 통해 입력과 출력의 관계를 설명, but 오차 발생

## 선형회귀의 개념과 목적

- 선형회귀(linear regression): 입력(독립변수)과 출력(종속변수) 쌍의 데이터를 통해 입력과 출력의 관계를 설명하는 선형 모델(일차식, 직선)을 찾는 문제
- 데이터 집합 D 가 주어졌을 때 (x,y) 관계를 설명할 수 있는 선형함수 y=w<sub>1</sub>x + w<sub>0</sub> + e 를 찾는 것

## 회귀함수를 사용한 새 데이터에 대한 예측

- 학습을 통해 회귀함수가 구해진 후, 새로운 입력 데이터 x<sub>new</sub>에 대한 예측 결과는 y=w<sub>1</sub>x + w<sub>0</sub> 를 통해 얻을 수 있다.

## 선형회귀의 비선형 문제를 위한 선형화의 개념

- x와 y가 선형 매핑의 관계로 표현할 수 없는 경우: 원래 데이터가 분포하는 형태에 따라 x와 y를 적절히 선형화하여 x'와 y'를 얻고, 이들 간의 선형 매핑관계 y'=mx'+b를 찾는 방식으로 진행

## 로지스틱 회귀의 개념 및 관련 용어/개념

- 로지스틱 회귀: 선형회귀분석의 출력을 범주형으로 제한한 회귀분석
  - 분류문제에 적용함
- 오즈비: 입력 x가 클래스 C1에 속할 확률과 C2에 속할 확률의 비율
- 로짓 함수: 오즈비에 대해 로그를 취한 함수

# 6장 군집화

## 군집화의 개념, 적용 방법 및 응용문제

- 군집화(clustering): 클래스에 대한 레이블을 가지지 않고 주어진 데이터를 분석하는 방법으로, 각 데이터의 유사도를 중심으로 몇 개의 그룹으로 나누는 것
- 군집화를 위한 데이터 집합의 경우 바람직한 출력값에 대한 정보가 없으므로 비지도학습을 수행해야 한다
- 군집화 응용문제: 영상, 이미지 분류 등

## K-평균 알고리즘의 수행 과정 및 특성

- K-평균 군집화 알고리즘: 데이터 집합을 K개의 그룹으로 묶는 알고리즘
- 수행과정
  ① 임의로 K개의 벡터를 선택하여 K개의 초기 대표 벡터 집합을 생성
  ③ 각 데이터에 대해 K개의 대표 벡터들과의 거리를 계산하고, 가장 가까운 벡터에 속하도록 레이블링
  ③ 새로운 클러스터에서 각각의 대표 벡터를 갱신
  ④ 반복여부 결정: 대표 벡터의 변화 or 설정된 반복 횟수 도달

## 계층적 군집화의 개념 및 각 방법의 개념

## 군집 간의 거리 계산 방식


# 7장 특징추출

## 특징추출의 개념과 목적 등

## 선형변환에 의한 차원축소의 개념와 예

## PCA, LDA의 목적, 개념 및 특성/문제점

## MDS, t-SNE, Isomap의 개념
