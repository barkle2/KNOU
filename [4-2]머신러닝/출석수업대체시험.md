# 1장 머신러닝 소개

## 1. 머신러닝의 개념

- 인공지능(강인공지능, 약인공지능) ⊃ 머신러닝 ⊃ 딥러닝
- 인공지능: 인간의 지능을 모방하여 문제해결을 위해 사람처럼 학습하고 이해하는 기계를 만드는 분야
- 머신러닝: 인간이 가지고 있는 고유의 지능적 기능 중 하나인 학습능력을 기계를 통해 구현하는 분야
  - 어떤 문제에 대해 명시적인 지식 표현이나 프로그램을 만드는 것이 어렵거나 불가능한 경우에 주로 사용함
- 딥러닝: 심층 신경망을 이용하여 데이터를 분석하는 학습에 초점을 둔 머신러닝 방법

## 2. 머신러닝의 처리 과정

- 학습 단계와 추론 단계로 구성
- 학습 단계: 주어진 데이터에 대한 분석을 통해 원하는 입·출력의 관계를 알려주는 매핑 함수(결정함수)를 찾는 과정
- 추론 단계: 학습을 통해 찾은 매핑 함수를 새롭게 주어지는 실제 데이터에 적용하여 결과를 얻는 과정

## 3. 머신러닝의 기본 요소

- 하나의 데이터는 n차원의 열벡터 **x** = [*x<sub>1</sub>, x<sub>2</sub>, ... , x<sub>n</sub>*]<sup>T</sup> 로 표현하며, 데이터 처리는 벡터 연산으로 정의됨
- 전체 데이터 집합이 이루는 분포 특성을 고려하여 특징을 추출하고 학습을 수행하는 것이 중요함
- 특징추출: 데이터에서 불필요한 정보를 제거하고 데이터 처리를 위한 핵심적 정보인 특징을 얻는 것
- 학습 시스템: 데이터로부터 학습을 통해 추출하고자 하는 정보를 표현하는 시스템
- 목적함수: 주어진 데이터 집합을 이용하여 학습 시스템이 달성해야 하는 목표를 기계가 알 수 있는 수학적 함수로 정의한 것
- 오차함수: 학습 시스템의 출력과 원하는 출력의 차이(오차)로 정의되는 목적함수
- 성능 평가 기준: 학습오차(학습 데이터 집합을 대상으로 계산된 오차), 테스트 오차(테스트 데이터 집합에 대한 오차), 일반화 오차(관찰될 수 있는 모든 데이터를 대상으로 하는 오차)
- 교차검증법: 제한된 데이터 집합을 이용하여 일반화 오차에 좀 더 근접한 오차값을 얻어 내는 방법

## 4. 머신러닝에서의 주제

- 머신러닝이 다루는 주제: 분류, 회귀, 군집화, 특징추출
- 분류: 입력 데이터가 어떤 부류(클래스)에 속하는지를 자동으로 판단하는 문제
  - 학습 데이터는 입력 데이터와 클래스 레이블의 쌍으로 구성됨
- 회귀: 학습을 통해 입력변수와 원하는 출력변수 사이의 매핑 관계를 분석하고 예측하는 것. 출력은 연속적인 실수값임
- 군집화: 주어지는 클래스 정보 없이 단순히 하나의 덩어리로 이루어진 데이터를 받아서, 데이터의 성질 또는 분포 특성을 분석하여 임의로 복수 개의 그룹으로 나누는 것
- 특징추출: 학습 시스템의 학습 결과로 특정 매핑 함수를 얻게 됨. 새로운 데이터 **x<sub>new</sub>** 는 매핑 함수 f를 통해 특징벡터 **z<sub>new</sub>** 로 변환되어 출력된다.

## 5. 학습 시스템 관련 개념

- 머신러닝의 유형: 지도학습, 비지도학습, 강화학습 등
- 지도학습(교사학습): 학습을 수행할 때 시스템이 출력해야 할 목표 출력값을 함께 제공하는 방식으로, 분류와 회귀 문제에 적합한 유형임
- 비지도학습(비교사학습): 학습할 때 목표 출력값에 대한 정보가 제공되지 않는 방식으로, 군집화 문제에 적합함
- 강화학습: 원하는 출력값을 모르거나 알 수 없는 경우 출력값에 대해 정확한 값의 형태로 교사 신호를 줄 수 없어서 출력값에 대한 교사 신호를 보상 형태로 주는 방식
- 과다적합: 학습 시스템이 학습 데이터에 대해서만 지나치게 적합한 형태로 결정경계를 형성하여 오히려 일반화 성능이 떨어지는 현상

# 4장 지도학습: 분류

## 분류 개념과 관련 용어

- 분류: 주어진 데이터 집합에 대해 이미 정의된 몇 개의 클래스(부류)로 입력을 구분하는 문제
- 분류기(classifier): 분류 문제를 다루는 학습 시스템
- 결정경계: 클래스로의 분류 기준

## 베이즈 분류기와 K-NN 분류기의 기본 개념/동작

- 베이즈 분류기
  - 후험확률에 대한 베이즈 정리로부터 유도된 판별함수 g<sub>i</sub>(**x**) = p(**x**|C<sub>i</sub>)p(C<sub>i</sub>) 를 이용하여 분류하는 방식
  - 새로운 데이터가 주어지면 각 클래스에 대해 g<sub>i</sub>(x)의 값을 계산한 후, 그 값이 가장 큰 클래스로 데이터를 분류함
  - 데이터의 확률분포함수를 미리 가정하고 이를 추정하여 분류에 활용
    - 미리 가정한 확률 모델이 주어진 데이터 분포에 적합하지 않으면 좋은 성능을 기대하기 힘들다.

- K-NN 분류기(K-Nearest Neighbor Classifier)
  - 주어진 데이터로부터 거리가 가까운 순서대로 K개의 데이터를 찾은 후, 그 중 가장 많은 수의 데이터가 속한 클래스로 할당하여 분류하는 방식
  - 분류 과정에서 새로운 데이터가 주어질 때마다 학습 데이터 전체와의 거리 계산을 통해 K개의 이웃 데이터를 선정해 주어야 하므로 항상 학습 데이터를 저장해야 함
    - 데이터의 수가 증가하면 그에 비례하여 계산량과 메모리도 함께 증가하는 문제점

## 이진 분류 문제에서의 베이즈 분류기에서의 결정경계의 형성

## 가우시안 베이즈 분류기의 공분산행렬 형태에 따른 판별함수

## K-NN 분류기 vs 가우시안 베이즈 분류기

## 거리 함수의 종류와 개념

## 분류기의 종류

# 5장 회귀

## 회귀의 개념 및 적용 방법의 종류

## 선형회귀의 개념과 목적

## 회귀함수를 사용한 새 데이터에 대한 예측

## 선형회귀의 비선형 문제를 위한 선형화의 개념

## 로지스틱 회귀의 개념 및 관련 용어/개념

# 6장 군집화

## 회귀의 개념 및 적용 방법의 종류

## 선형회귀의 개념과 목적

## 회귀함수를 사용한 새 데이터에 대한 예측

## 선형회귀의 비선형 문제를 위한 선형화의 개념

## 로지스틱 회귀의 개념 및 관련 용어/개념

# 7장 특징추출

## 특징추출의 개념과 목적 등

## 선형변환에 의한 차원축소의 개념와 예

## PCA, LDA의 목적, 개념 및 특성/문제점

## MDS, t-SNE, Isomap의 개념
