{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 Multiple Regression\n",
    "\n",
    "## 01 Introduction\n",
    "\n",
    "### 1. Introduction\n",
    "\n",
    "- This lecture discusses the case of regression analysis with multiple predictors. The news is mainly the model search aspect, namely among a set of potential descriptive variables to look for a subset that describes the response sufficiently well.\n",
    "- 이 강의는 다중 예측 변수를 사용한 회귀 분석 사례에 대해 논의합니다. 주로 모델 탐색 측면을 다루며, 즉 응답을 충분히 설명하는 부분 집합을 찾기 위해 잠재적 설명 변수 집합 중에서 선택하는 것입니다.\n",
    "\n",
    "- The basic model for multiple regression analysis is \n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?y=\\beta_0&plus;\\beta_1&space;x_1&plus;\\cdots&plus;\\beta_k&space;x_k&plus;\\epsilon\">\n",
    "\n",
    "where <img src=\"https://latex.codecogs.com/svg.image?x_1,\\cdots,x_k\"> are explanatory variables(also called predictors) and the parameters <img src=\"https://latex.codecogs.com/svg.image?\\beta_1,\\cdots,\\beta_k\"> can be estimated using the method of least squares.  \n",
    "여기서 <img src='https://latex.codecogs.com/svg.image?x_1,\\cdots,x_k'>는 설명 변수(또는 예측 변수)이며, 파라미터 <img src='https://latex.codecogs.com/svg.image?\\beta_1,\\cdots,\\beta_k'>는 최소 제곱법을 사용하여 추정될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Model and Estimation\n",
    "\n",
    "### 1. Linear Model\n",
    "\n",
    "- One very general form for the model:  \n",
    "<img src=\"https://latex.codecogs.com/svg.image?Y=f(X_1,X_2,X_3)&plus;\\epsilon\">\n",
    "\n",
    "where f is some unknown function and ε is an error\n",
    "\n",
    "- Since we usually don't have enough data to try to estimate f directly, we usually have to assume that it has some more restricted form, perhaps linear as in  \n",
    "- 보통 우리는 f를 직접 추정하기에 충분한 데이터가 없기 때문에, 보다 제한된 형식을 갖는 것으로 가정해야 합니다. 아마도 선형적인 형태일 것입니다.\n",
    "<img src=\"https://latex.codecogs.com/svg.image?Y=\\beta_0&plus;\\beta_1&space;X_1&plus;\\beta_2&space;X_2&plus;\\beta_3&space;X_3&plus;\\epsilon\">\n",
    "\n",
    "- In a linear model the parameters enter linearly - the predictors do not have to be linear.\n",
    "- 선형 모델에서는 모수(파라미터)가 선형적으로 입력되며, 예측 변수는 선형적일 필요가 없습니다.\n",
    "\n",
    "### 2. Matrix Representation\n",
    "\n",
    "- Given the actual data, we may write:  \n",
    "<img src=\"https://latex.codecogs.com/svg.image?Y=\\beta_0&plus;\\beta_1&space;X_1&plus;\\beta_2&space;X_2&plus;\\beta_3&space;X_3&plus;\\epsilon\">\n",
    "\n",
    "- Let\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?Y=\\begin{pmatrix}y_1\\\\y_2\\\\\\vdots\\\\y_n\\end{pmatrix}\">\n",
    "<img src=\"https://latex.codecogs.com/svg.image?X=\\begin{pmatrix}1&x_{11}&x_{12}&x_{13}\\\\1&x_{21}&x_{22}&x_{23}\\\\1&\\cdots&\\cdots&\\cdots\\\\1&x_{n1}&x_{n2}&x_{n3}\\\\\\end{pmatrix}\">\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\epsilon=\\begin{pmatrix}\\epsilon_1\\\\\\epsilon_2\\\\\\vdots\\\\\\epsilon_n\\end{pmatrix}\"> <br>\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?Y=X\\beta&plus;\\epsilon\">\n",
    "\n",
    "### 3. Least squares estimation\n",
    "\n",
    "- Least square estimate of β, called <img src=\"https://latex.codecogs.com/svg.image?\\hat\\beta\"> minimizes SSE\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\sum{\\epsilon_i^2}=\\epsilon^T\\epsilon=(y-X\\beta)^T(y-X\\beta)\"> <br>\n",
    "\n",
    "편미분값을 0으로 만드는 β 값을 찾으면 된다.\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\frac{\\partial}{\\partial\\beta}(y-X\\beta)^T(y-X\\beta)\"> <br>\n",
    "<img src=\"https://latex.codecogs.com/svg.image?=-2X^TY&plus;2X^TX\\beta=0\"> <br>\n",
    "\n",
    "- Differentiating with respect to β and setting to zero, we find that <img src=\"https://latex.codecogs.com/svg.image?\\hat{\\beta}\"> satisfies\n",
    "- β에 대해 미분하고 그 결과가 0이 되는 β 값이 <img src=\"https://latex.codecogs.com/svg.image?\\hat{\\beta}\">입니다.\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\hat{\\beta}=(X^T&space;X)^{-1}X^T&space;Y\">\n",
    "\n",
    "- Predicted values: <img src=\"https://latex.codecogs.com/svg.image?\\hat{y}=X\\hat{\\beta}=X(X^T&space;X)^{-1}X^T&space;y=Hy,\\;\\;\\;H=X(X^T&space;X)^{-1}X^T\">  \n",
    "Residuals: <img src=\"https://latex.codecogs.com/svg.image?\\hat{\\epsilon}=y-X\\hat{\\beta}=y-\\hat{y}=(I-H)y\">  \n",
    "Residual sum of squares: <img src=\"https://latex.codecogs.com/svg.image?\\hat{\\epsilon}^T\\hat{\\epsilon}=y^T(I-H)(I-H)y=y^T(I-H)y\">\n",
    "\n",
    "- Assume the errors are uncorrelated and have equal variance, <img src=\"https://latex.codecogs.com/svg.image?Var(\\epsilon)=I\\sigma^2\">\n",
    "- 오차가 상관되지 않고 동일한 분산을 가졌다고 가정하면, <img src=\"https://latex.codecogs.com/svg.image?Var(\\epsilon)=I\\sigma^2\">\n",
    "\n",
    "### 4. Mean and variance of <img src=\"https://latex.codecogs.com/svg.image?\\hat{\\beta}\">\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\hat{\\beta}=(X^T&space;X)^{-1}X^T&space;Y\">\n",
    "\n",
    "- Mean <img src=\"https://latex.codecogs.com/svg.image?E\\hat{\\beta}=(X^T&space;X)^{-1}X^T&space;X\\beta=\\beta\"> unbiased\n",
    "- <img src=\"https://latex.codecogs.com/svg.image?Var(\\hat{\\beta})=Var(Ay)=A\\cdot&space;Var(y)A^T\">\n",
    "<img src=\"https://latex.codecogs.com/svg.image?=(X^T&space;X)^{-1}X^T\\sigma^2&space;I&space;X(X^T&space;X)^{-1}=(X^T&space;X)^{-1}\\sigma^2\">\n",
    "\n",
    "- Standard error of <img src=\"https://latex.codecogs.com/svg.image?\\hat{\\beta_i}:\\;\\;se(\\hat{\\beta_i})=\\sqrt{(X^T&space;X)_{ii}^{-1}\\hat{\\sigma}}\">\n",
    "\n",
    "### 5. Estimating <img src=\"https://latex.codecogs.com/svg.image?\\sigma^2\">\n",
    "\n",
    "- ANOVA Table\n",
    "\n",
    "||SS|Df|MS|F-value|\n",
    "|-|-|-|-|-|\n",
    "|Regress|SSR|p|MSR|MSR/MSE|\n",
    "|Error|SSE|n-p-1|MSE||\n",
    "|Total|SST|n-1|||\n",
    "\n",
    "<br>\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\hat{\\sigma}^2=\\frac{SSE}{n-p-1}:MSE\">  \n",
    "\n",
    "- Coefficient of determination: <img src=\"https://latex.codecogs.com/svg.image?R^2=\\frac{SSR}{SST}\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Example\n",
    "\n",
    "```R\n",
    "result = lm(y~a+b+c+d)\n",
    "summary(result)\n",
    "anova(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Inference: Example\n",
    "\n",
    "### 1. Recall: The model\n",
    "\n",
    "- Model\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?y=X\\beta&plus;\\epsilon\">\n",
    "\n",
    "- We assume that the errors are independent and identically normally distributed with mean 0 and variance <img src=\"https://latex.codecogs.com/svg.image?y=\\sigma^2\">, i.e.\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\epsilon\\sim&space;N(0,\\sigma^2&space;I)\"> <br>\n",
    "<img src=\"https://latex.codecogs.com/svg.image?y\\sim&space;N(X\\beta,\\sigma^2&space;I)\">\n",
    "\n",
    "### 2. Examples\n",
    "\n",
    "- Let's illustrate this test and others using an old economic dataset on 50 different countries. These data are averages over 1960-1970 (to remove business cycle or other short-term fluctuations).\n",
    "- 이 테스트와 다른 테스트를 설명하기 위해 1960년부터 1970년까지 50개 국가에 대한 오래된 경제 데이터를 사용해보겠습니다. 이 데이터는 비즈니스 사이클이나 기타 단기적 변동을 제거하기 위해 1960년부터 1970년까지의 평균입니다.\n",
    "\n",
    "- dpi is per-capita disposable income in U.S. dollars; ddpi is the percent rate of change in per capita disposable income; sr is aggregate personal saving divided by disposable income. The percentage population under 15(pop 15) and over 75(pop 75) are also recorded. The data come from Belsley, Kuh, and Welsch(1980).  \n",
    "- dpi는 1인당 처분가능소득(달러)이고; ddpi는 1인당 처분가능소득의 변화율입니다. sr은 처분가능소득에 대한 종합 개인 저축입니다. 15세 미만 인구 백분율(pop 15)과 75세 이상 인구 백분율(pop 75)도 기록되어 있습니다. 이 데이터는 Belsley, Kuh 및 Welsch(1980)에서 가져온 것입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
