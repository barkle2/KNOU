plot(RC_Chpt25_table[,1], RC_Chpt25_table[,2], type='n')
text(RC_Chpt25_table[,1], RC_Chpt25_table[,2], row.names(RC_Chpt25_table), col=RC_Chpt25_col)
RC_Chpt25_col = ifelse(RC_Chpt25_table[,3] > 10, "darkgreen",
ifelse(RC_Chpt25_table[,3] < -10, "red", "grey"))
plot(RC_Chpt25_table[,1], RC_Chpt25_table[,2], type='n')
text(RC_Chpt25_table[,1], RC_Chpt25_table[,2], row.names(RC_Chpt25_table), col=RC_Chpt25_col)
# RC_Chpt25_table 3열에 단어별 출현빈도 차이를 추가합니다.
RC_Chpt25_table = cbind(RC_Chpt25_table, RC_Chpt25_table[,1]-RC_Chpt25_table[,2])
# 챕터 2에 더 많이 나타난 단어는 초록, 챕터 5에 더 많이 나타난 단어는 빨강
RC_Chpt25_col = ifelse(RC_Chpt25_table[,3] > 10, "darkgreen",
ifelse(RC_Chpt25_table[,3] < -10, "red", "grey"))
plot(RC_Chpt25_table[,1], RC_Chpt25_table[,2], type='n')
text(RC_Chpt25_table[,1], RC_Chpt25_table[,2], row.names(RC_Chpt25_table), col=RC_Chpt25_col)
RC_Chpt25_table[,1]
RC_Chpt25_table[,2]
t(RC_Chpt25_table[,1])
RC_Chpt25_table *%* t(RC_Chpt25_table[,1])
diag(RC_Chpt25_table *%* t(RC_Chpt25_table[,1]))
RC_Chpt25_table %*% t(RC_Chpt25_table[,1])
t(RC_Chpt25_table[,1])
diag(RC_Chpt25_table)
diag(t(RC_Chpt25_table[,1]))
diag(RC_Chpt25_table[,1])
t(diag(RC_Chpt25_table[,1]))
diag(RC_Chpt25_table[,1]) %*% t(diag(RC_Chpt25_table[,1]))
sqrt(diag(RC_Chpt25_table[,1]) %*% t(diag(RC_Chpt25_table[,1])))
RC_Chpt25_table[,2]
RC_Chpt25_table[,2][1]
RC_Chpt25_table[,2][,1]
RC_Chpt25_table[,2][:]
RC_Chpt25_table[,2]
RC_Chpt25_table[,2][1]
RC_Chpt25_table[,2][2]
RC_Chpt25_table[,2][,1]
RC_Chpt25_table[,2][,2]
RC_Chpt25_list
RC_Chpt2_v9 = lapply(RC_Chpt2_v8, FUN=function(x, lev){table(factor(x, lev, ordered=T))}, lev=RC_Chpt25_list)
RC = scan("http://www.gutenberg.org/files/521/521-0.txt", what="character",
encoding="UTF-8", sep='\n')
RC = scan("http://www.gutenberg.org/files/521/521-0.txt", what="character",
encoding="UTF-8", sep='\n')
RC_Chpt = grep(RC, pattern="CHAPTER")
RC_End = grep(tolower(RC), pattern="end of the project gutenberg")-1
RC_Chpt = grep(RC, pattern="CHAPTER")[21:40]
RC_End = RC_Chpt[2:20]
RC_End = RC_Chpt[2:20]-1
RC_End = c(RC_Chpt[2:20]-1, 9318)
RC_body = RC[(RC_Chpt[1]):RC_End]
RC_body = RC[RC_Chpt:RC_End]
RC_Chpt:RC_End
nberg 프로젝트에서 전체 파일을 읽어옵니다.
RC <- scan("http://www.gutenberg.org/files/521/521-0.txt", what="character",
encoding="UTF-8", sep='\n')
# 로빈슨 크루소는 20개의 챕터로 이뤄져 있습니다.
# 521-0.txt 파일을 보면 CHAPTER 단어가 40번 나옵니다.(차례 20번, 본문 20번)
# 21~40번의 CHAPTER 단어가 나타나는 부분이 CHAPTER의 시작부분입니다.
RC_Chpt_Start <- grep(RC, pattern="CHAPTER")
RC_Chpt_Start <- RC_Chpt_Start[21:40]
# 챕터 2와 챕터 5를 읽어옵니다.
RC_Chpt2 = RC[RC_Chpt[2]:(RC_Chpt[3]-1)]
RC_Chpt5 = RC[RC_Chpt[5]:(RC_Chpt[6]-1)]
# 챕터 2와 5에 나오는 단어 리스트를 생성한다.
RC_Chpt25_list = unique(c(RC_Chpt2_v8, RC_Chpt5_v8))
# 202035-368086, 김동현
# gutenberg 프로젝트에서 전체 파일을 읽어옵니다.
RC <- scan("http://www.gutenberg.org/files/521/521-0.txt", what="character",
encoding="UTF-8", sep='\n')
# 로빈슨 크루소는 20개의 챕터로 이뤄져 있습니다.
# 521-0.txt 파일을 보면 CHAPTER 단어가 40번 나옵니다.(차례 20번, 본문 20번)
# 21~40번의 CHAPTER 단어가 나타나는 부분이 CHAPTER의 시작부분입니다.
RC_Chpt_Start <- grep(RC, pattern="CHAPTER")
RC_Chpt_Start <- RC_Chpt_Start[21:40]
# 챕터 2와 챕터 5를 읽어옵니다.
RC_Chpt2 = RC[RC_Chpt[2]:(RC_Chpt[3]-1)]
RC_Chpt5 = RC[RC_Chpt[5]:(RC_Chpt[6]-1)]
print(RC_Chpt2)
print(RC_Chpt5)
# 나누어진 행들을 하나의 문자열로 연결합니다.
RC_Chpt2_v1 = paste(RC_Chpt2, collapse=" ")
# 합치면서 행 사이에 빈칸을 추가했기 때문에 395개의 문자가 늘었습니다.
sum(nchar(RC_Chpt2))
nchar(RC_Chpt2_v1)
# 's 를 삭제합니다.
RC_Chpt2_v2 = gsub(RC_Chpt2_v1, pattern="'s", replacement="")
nchar(RC_Chpt2_v2)
# 아포스트로피(')와 하이픈(-)을 제외한 나머지 문장부호들을 제거합니다.
RC_Chpt2_v3 = gsub(RC_Chpt2_v2, pattern="([^[:alnum:][:blank:]'-])", replacement="")
nchar(RC_Chpt2_v3)
# 대문자를 소문자로 변환합니다.
RC_Chpt2_v4 = tolower(RC_Chpt2_v3)
nchar(RC_Chpt2_v4)
# 문서를 공백 기준으로 나누어 단어 단위로 분리합니다.
RC_Chpt2_v5 = unlist(strsplit(RC_Chpt2_v4, " "))
sum(nchar(RC_Chpt2_v5))
# 불용어와 빈단어를 삭제합니다.
library(stopwords)
RC_Chpt2_v6 = RC_Chpt2_v5[! RC_Chpt2_v5 %in% c(stopwords())]
sum(nchar(RC_Chpt2_v6))
RC_Chpt2_v7 = gsub(RC_Chpt2_v6, pattern="'", replacement="")
sum(nchar(RC_Chpt2_v7))
# 단어를 표제어로 변환합니다.
library(textstem)
RC_Chpt2_v8 = lemmatize_strings(RC_Chpt2_v7)
sum(nchar(RC_Chpt2_v8))
RC_Chpt2_v8
# 많이 사용된 단어를 볼 수 있도록 도수분포표를 작성합니다.
RC_Chpt2_table = sort(table(RC_Chpt2_v8), decreasing=T)
print(RC_Chpt2_table)
RC_Chpt2_prop_table = sort(prop.table(table(RC_Chpt2_v8)), decreasing=T)
print(RC_Chpt2_prop_table)
# 챕터 5
# 나누어진 행들을 하나의 문자열로 연결합니다.
RC_Chpt5_v1 = paste(RC_Chpt5, collapse=" ")
# 합치면서 행 사이에 빈칸을 추가했기 때문에 395개의 문자가 늘었습니다.
sum(nchar(RC_Chpt5))
nchar(RC_Chpt5_v1)
# 's 를 삭제합니다.
RC_Chpt5_v2 = gsub(RC_Chpt5_v1, pattern="'s", replacement="")
nchar(RC_Chpt5_v2)
# 아포스트로피(')와 하이픈(-)을 제외한 나머지 문장부호들을 제거합니다.
RC_Chpt5_v3 = gsub(RC_Chpt5_v2, pattern="([^[:alnum:][:blank:]'-])", replacement="")
nchar(RC_Chpt5_v3)
# 대문자를 소문자로 변환합니다.
RC_Chpt5_v4 = tolower(RC_Chpt5_v3)
nchar(RC_Chpt5_v4)
# 문서를 공백 기준으로 나누어 단어 단위로 분리합니다.
RC_Chpt5_v5 = unlist(strsplit(RC_Chpt5_v4, " "))
sum(nchar(RC_Chpt5_v5))
# 불용어와 빈단어를 삭제합니다.
RC_Chpt5_v6 = RC_Chpt5_v5[! RC_Chpt5_v5 %in% c(stopwords())]
sum(nchar(RC_Chpt5_v6))
RC_Chpt5_v7 = gsub(RC_Chpt5_v6, pattern="'", replacement="")
sum(nchar(RC_Chpt5_v7))
# 단어를 표제어로 변환합니다.
RC_Chpt5_v8 = lemmatize_strings(RC_Chpt5_v7)
sum(nchar(RC_Chpt5_v8))
RC_Chpt5_v8
# 많이 사용된 단어를 볼 수 있도록 도수분포표를 작성합니다.
RC_Chpt5_table = sort(table(RC_Chpt5_v8), decreasing=T)
print(RC_Chpt5_table)
RC_Chpt2_prop_table = sort(prop.table(table(RC_Chpt2_v8)), decreasing=T)
print(RC_Chpt2_prop_table)
# 챕터 2와 5에 나오는 단어 리스트를 생성한다.
RC_Chpt25_list = unique(c(RC_Chpt2_v8, RC_Chpt5_v8))
# 생성한 단어 리스트를 기준으로 도수분포표를 작성한다.
RC_Chpt2_table = table(factor(RC_Chpt2_v8, levels=RC_Chpt25_list, ordered=T))
RC_Chpt5_table = table(factor(RC_Chpt5_v8, levels=RC_Chpt25_list, ordered=T))
# 챕터5와 챕터2 사이의 출현빈도의 차값으로 도수분포표를 작성한다.
RC_Chpt5_2_table = sort(RC_Chpt5_table - RC_Chpt2_table)
# 출현빈도의 차가 -5보다 작거나 5보다 큰 경우만 남긴다.
RC_Chpt5_2_table = RC_Chpt5_2_table[abs(RC_Chpt5_2_table)>5]
# 도수분포표를 출력한다.
RC_Chpt5_2_table
# 막대그래프를 출력한다.
barplot(RC_Chpt5_2_table, las=2)
# 공통 단어의 행렬을 만듭니다.
RC_Chpt25_table = cbind(RC_Chpt2_table, RC_Chpt5_table)
# 챕터의 빈도수 합으로 워드 클라우드를 생성합니다.
library(wordcloud)
commonality.cloud(RC_Chpt25_table, max.words=100, random.order=FALSE)
# 챕터의 빈도수 차로 워드 클라우드를 생성합니다.
comparison.cloud(RC_Chpt25_table, max.words=100, random.order=FALSE)
# RC_Chpt25_table 3열에 단어별 출현빈도 차이를 추가합니다.
RC_Chpt25_table = cbind(RC_Chpt25_table, RC_Chpt25_table[,1]-RC_Chpt25_table[,2])
# 챕터 2에 더 많이 나타난 단어는 초록, 챕터 5에 더 많이 나타난 단어는 빨강
RC_Chpt25_col = ifelse(RC_Chpt25_table[,3] > 10, "darkgreen",
ifelse(RC_Chpt25_table[,3] < -10, "red", "grey"))
plot(RC_Chpt25_table[,1], RC_Chpt25_table[,2], type='n')
text(RC_Chpt25_table[,1], RC_Chpt25_table[,2], row.names(RC_Chpt25_t
# 챕터 2와 5에 나오는 단어 리스트를 생성한다.
RC_Chpt25_list = unique(c(RC_Chpt2_v8, RC_Chpt5_v8))
# 챕터 2와 5에 나오는 단어 리스트를 생성한다.
RC_Chpt25_list = unique(c(RC_Chpt2_v8, RC_Chpt5_v8))
factor(RC_Chpt2_v8)
install.packages('plyr')
library(plyr)
count(RC_Chpt2_v8)
count(RC_Chpt2_v8, RC_Chpt25_list)
? count
count(RC_Chpt2_v8, vars=RC_Chpt25_list)
count(RC_Chpt2_v8, vars=TRUE)
count(RC_Chpt2_v8)
RC_25 = lapply(RC_Chpt2_v8, FUN=function(x, lev){table(factor(x, lev, ordered=T))}, RC_Chpt2_list)
# 챕터 2와 5에 나오는 단어 리스트를 생성한다.
RC_Chpt25_list = unique(c(RC_Chpt2_v8, RC_Chpt5_v8))
RC_25 = lapply(RC_Chpt2_v8, FUN=function(x, lev){table(factor(x, lev, ordered=T))}, RC_Chpt25_list)
RC_25
RC_25 = lapply(RC_Chpt2_v8, FUN=function(x, lev){table(factor(x, lev, ordered=T))}, RC_Chpt25_list)
RC_25
RC_25_2 = matrix(unlist(RC_25), nrow=length(RC_25), byrow=TRUE)
RC25 = cbind(RC_Chpt2_v8, RC_Chpt5_v8)
RC25 = c(RC_Chpt2_v8, RC_Chpt5_v8)
RC25 = rbind(RC_Chpt2_v8, RC_Chpt5_v8)
RC25
view(RC25)
View(RC25)
RC25_DTM = lapply(RC25, FUN=function(x, lev){table(factor(x, lev, ordered=T))}, RC_Chpt25_list)
View(RC25_DTM)
RC25_DTM = matrix(unlist(RC25_DTM), nrow=2, byrow=TRUE)
View(RC25_DTM)
length(RC25_DTM)
RC25 = rbind(RC_Chpt2_v8, RC_Chpt5_v8)
RC25_DTM = lapply(RC25, FUN=function(x, lev){table(factor(x, lev, ordered=T))}, RC_Chpt25_list)
length(RC25_DTM)
RC25_DTM = matrix(unlist(RC25_DTM), nrow=length(RC25_DTM), byrow=TRUE)
dim(RC25_DTM)
dim(RC25_DTM>0)
sum(RC25_DTM>0)
sum(RC25_DTM==0)
RC25 = rbind(RC_Chpt2_v8, RC_Chpt5_v8)
View(RC25)
dim(RC25)
dim(RC_Chpt25_list)
RC_Chpt2_table
head(RC_Chpt2_table)
typeof(RC_Chpt2_table)
install.packages('lsa')
library(lsa)
td=tempfile()
dir.create(td)
RC_Chpt2_v8
write(RC_Chpt2_v8, file=paste(td, "CH2", sep='\'))
)
z
q
write(RC_Chpt2_v8, file=paste(td, "CH2", sep='\'))
write(RC_Chpt2_v8, file=paste(td, "CH2", sep="\"))
write(RC_Chpt2_v8, file=paste(td, "CH2", sep="\"))
RC_Chpt2_v8
write(RC_Chpt2_v8, file=paste(td, "CH2", sep="/"))
write(RC_Chpt5_v8, file=paste(td, "CH5", sep="/"))
myMatrix = textmatrix(td, minWordLength = 1)
myMatrix
res = lsa:cosine(myMatrix[,1], myMatrix[,2])
res = lsa::cosine(myMatrix[,1], myMatrix[,2])
res
cor(RC_Chpt2_v8, RC_Chpt5_v8)
corr(RC_Chpt2_v8, RC_Chpt5_v8)
myMatrix
stringdist(RC_Chpt2_v8, RC_Chpt5_v8, method="cosine")
install.packages('stringdist')
library(stringdist)
stringdist(RC_Chpt2_v8, RC_Chpt5_v8, method="cosine")
?stringdist
stringdistmatrix(RC_Chpt2_v8, RC_Chpt5_v8, method="cosine")
myMatrix = textmatrix(td, minWordLength = 0)
myMatrix
res = lsa::cosine(myMatrix[,1], myMatrix[,2])
res
myMatrix = textmatrix(td)
myMatrix
myMatrix = textmatrix(td)
myMatrix
res = lsa::cosine(myMatrix[,1], myMatrix[,2])
res
lsa::cosine(myMatrix[,1], myMatrix[,2])
library(lsa)
td=tempfile()
dir.create(td)
write(RC_Chpt2_v8, file=paste(td, "CH2", sep="/"))
write(RC_Chpt5_v8, file=paste(td, "CH5", sep="/"))
myMatrix = textmatrix(td)
lsa::cosine(myMatrix[,1], myMatrix[,2])
lsa::cosine(myMatrix[,1], myMatrix[,1])
lsa::cosine(myMatrix[,1], myMatrix[,2])
setwd("D:/공부/방송통신대/3학년 2학기/실험계획과응용")
y = c(4,5,8,5,7,8)
A = c(1,2,3,1,2,3)
A = c(rep(1,6), rep(2,6), rep(3,6))
A = c(1,2,3,1,2,3)
B = c(1,1,1,2,2,2)
c = data.frame(y, A, B)
c
c$A = factor(c$A, levels=c(1,2,3), labels=c("A1", "A2", "A3"))
c$A = factor(c$A, levels=c(1,2,3), labels=c("A1", "A2", "A3"))
c$B = factor(c$B, levels=c(1,2), labels=c("B1", "B2"))
c
y = c(4,5,8,5,7,8)
A = c(1,2,3,1,2,3)
B = c(1,1,1,2,2,2)
c = data.frame(y, A, B)
c$A = factor(c$A, levels=c(1,2,3), labels=c("A1", "A2", "A3"))
c$B = factor(c$B, levels=c(1,2), labels=c("B1", "B2"))
c
anova <- aov(y ~ A*B+Error(A/B), data=c)
summary(anova)
with(c, interaction.plot(x.factor=A, trace.factor=B, response=y, fun=mean, type='b', legend=T))
anova <- aov(y ~ A*B+Error(A/B), data=c)
summary(anova)
4.5*4.5+6*6+8*8+(17/3)*(17/3)+(20/3)*(20/3)
37*37/6
10.3*10.3+26.1*26.1+37.6*37.6+20.3*20.3+30.9*30.9+22.8*22.8
4087.8/3
4087.8/12
y = c(1.0,4.2,5.3,0.3,3.3,6.2,3.2,6.1,6.6,2.6,5.3,7.1,1.3,3.1,6.0,1.9,4.1,6.4)
A = rep(c(1,2,3),3)
A = rep(c(1,2,3),6)
B = c(rep(1,6), rep(2,6), rep(3,6))
c = data.frame(y, A, B)
c
c$A = factor(c$A, levels=c(1,2,3), labels=c("A1", "A2", "A3"))
c$B = factor(c$B, levels=c(1,2,3), labels=c("B1", "B2", "B3"))
c
with(c, interaction.plot(x.factor=A, trace.factor=B, response=y, fun=mean, type='b', legend=T))
anova <- aov(y ~ A*B+Error(A/B), data=c)
summary(anova)
4.5*4.5+6*6+8*8
9*9+12*12+16*16 - 37*37/6
(9*9+12*12+16*16)/2 - 37*37/6
(17*17+20*20)/2-37*37/6
37*37/6
(9*9+12*12+16*16)/2
y = c(4,5,8,5,7,8)
A = c(1,2,3,1,2,3)
B = c(1,1,1,2,2,2)
c = data.frame(y, A, B)
c
c$A = factor(c$A, levels=c(1,2,3), labels=c("A1", "A2", "A3"))
c$B = factor(c$B, levels=c(1,2), labels=c("B1", "B2"))
c
with(c, interaction.plot(x.factor=A, trace.factor=B, response=y, fun=mean, type='b', legend=T))
anova <- aov(y ~ A*B+Error(A/B), data=c)
summary(anova)
(9*9+12*12+16*16)/2
240.5-228.17
y = c(4,5,8,5,7,8)
A = c(1,2,3,1,2,3)
B = c(1,1,1,2,2,2)
c = data.frame(y, A, B)
c$A = factor(c$A, levels=c(1,2,3), labels=c("A1", "A2", "A3"))
c$B = factor(c$B, levels=c(1,2), labels=c("B1", "B2"))
anova <- aov(y ~ A*B+Error(A/B), data=c)
summary(anova)
(12*12+7*7+10*10)/3
29*29/9
(12*12+7*7+10*10)/3 - 29*29/9
y = c(3,2,4,2,3,5,3,1,6)
y = c(3,2,4,2,3,5,3,1,6)
A = c(1,2,3,1,2,3,1,2,3)
B = c(1,1,1,2,2,2,3,3,3)
C = c(1,3,2,2,1,3,3,2,1)
df = data.frame(y, A, B, C)
df
anova = aov(y ~ A+B+C, data=df)
summary(anova)
y = c(3,2,4,2,3,5,3,1,6)
A = factor(c(1,2,3,1,2,3,1,2,3))
B = factor(c(1,1,1,2,2,2,3,3,3))
C = factor(c(1,3,2,2,1,3,3,2,1))
df = data.frame(y, A, B, C)
df
anova = aov(y ~ A+B+C, data=df)
summary(anova)
y = c(3,2,4,2,3,5,3,1,6)
A = factor(c(1,2,3,1,2,3,1,2,3))
B = factor(c(1,1,1,2,2,2,3,3,3))
C = c(1,3,2,2,1,3,3,2,1)
df = data.frame(y, A, B, C)
df
anova = aov(y ~ A+B+C, data=df)
summary(anova)
y = c(3,2,4,2,3,5,3,1,6)
A = factor(c(1,2,3,1,2,3,1,2,3))
B = factor(c(1,1,1,2,2,2,3,3,3))
C = factorc(1,3,2,2,1,3,3,2,1)
df = data.frame(y, A, B, C)
df
anova = aov(y ~ A+B+C, data=df)
summary(anova)
y = c(3,2,4,2,3,5,3,1,6)
A = factor(c(1,2,3,1,2,3,1,2,3))
B = factor(c(1,1,1,2,2,2,3,3,3))
C = factor(c(1,3,2,2,1,3,3,2,1))
df = data.frame(y, A, B, C)
df
anova = aov(y ~ A+B+C, data=df)
summary(anova)
y = c(3,2,4,2,3,5,3,1,6)
A = factor(c(1,2,3,1,2,3,1,2,3))
B = factor(c(1,1,1,2,2,2,3,3,3))
C = factor(c(1,3,2,2,1,3,3,2,1))
df = data.frame(y, A, B, C)
df
anova = aov(y ~ A+B+C, data=df)
summary(anova)
13/1.625
152/8
152*152/8
12*12/8
900/8
y = c(10,15,18,23,18,18,24,26)
A = factor(c(0,1,0,1,0,1,0,1))
B = factor(c(0,0,1,1,0,0,1,1))
C = factor(c(0,0,0,0,1,1,1,1))
df = data.frame(y, A, B, C)
anova = aov(y ~ A*B*C, data=df)
summary(anova)
40.3/8
0.3/4
11.3/4
1.9/4
40.3*40.3/8
0.3*0.3/8
11.3*11.3/8
0.1*0.1/8
1.5*1.5/8
.81/8
1.9*1.9/8
y = c(3.1,3.3,6.3,6.7,4.1,4.0,6.5,6.3)
y = c(3.1,3.3,6.3,6.7,4.1,4.0,6.5,6.3)
A = factor(c(0,1,0,1,0,1,0,1))
B = factor(c(0,0,1,1,0,0,1,1))
C = factor(c(0,0,0,0,1,1,1,1))
block = factor(c(1,0,0,0,1,1,1,0))
df = data.frame(y, A, B, C, block)
df
anova = aov(y~block+A+B+C+A*B+A*C+B*C)
summary(anova)
anova = aov(y~block+A+B+C+A*B+A*C+B*C, data=df)
summary(anova)
y = c(3.1,3.3,6.3,6.7,4.1,4.0,6.5,6.3)
A = c(0,1,0,1,0,1,0,1)
B = c(0,0,1,1,0,0,1,1)
C = c(0,0,0,0,1,1,1,1)
block = c(1,0,0,0,1,1,1,0)
df = data.frame(y, A, B, C, block)
upto4 = aov(y~(A+B+C)^3, data=df)
y = c(3.1,3.3,6.3,6.7,4.1,4.0,6.5,6.3)
A = c(0,1,0,1,0,1,0,1)
B = c(0,0,1,1,0,0,1,1)
C = c(0,0,0,0,1,1,1,1)
block = c(1,0,0,0,1,1,1,0)
df = data.frame(y, A, B, C, block)
df$A = factor(df$A, levels=c(0,1))
df$B = factor(df$B, levels=c(0,1))
df$C = factor(df$C, levels=c(0,1))
df$block = factor(df$block, levels=c(0,1))
upto4 = aov(y~(A+B+C)^3, data=df)
summary(upto4)
anova = aov(y~block+A+B+C+A*B+A*C+B*C, data=df)
summary(anova)
anova = aov(y~block+A+B+C, data=df)
summary(anova)
summary(upto4)
summary(anova)
anova = aov(y~block+A+B+C+A*B+A*C+B*C, data=df)
summary(anova)
anova = aov(y~block+A+B+C, data=df)
summary(anova)
y = c(3.1,3.3,6.3,6.7,4.1,4.0,6.5,6.3)
A = c(0,1,0,1,0,1,0,1)
B = c(0,0,1,1,0,0,1,1)
C = c(0,0,0,0,1,1,1,1)
block = c(1,0,0,0,1,1,1,0)
df = data.frame(y, A, B, C, block)
df$A = factor(df$A, levels=c(0,1))
df$B = factor(df$B, levels=c(0,1))
df$C = factor(df$C, levels=c(0,1))
df$block = factor(df$block, levels=c(0,1))
upto4 = aov(y~(A+B+C)^3, data=df)
summary(upto4)
df
anova = aov(y~block+A+B+C, data=df)
summary(anova)
anova = aov(y~A+B+C, data=df)
summary(anova)
y = c(3.1,3.3,6.3,6.7,4.1,4.0,6.5,6.3)
A = c(0,1,0,1,0,1,0,1)
B = c(0,0,1,1,0,0,1,1)
C = c(0,0,0,0,1,1,1,1)
block = c(0,1,1,1,0,0,0,1)
df = data.frame(y, A, B, C, block)
df$A = factor(df$A, levels=c(0,1))
df$B = factor(df$B, levels=c(0,1))
df$C = factor(df$C, levels=c(0,1))
df$block = factor(df$block, levels=c(0,1))
upto4 = aov(y~(A+B+C)^3, data=df)
summary(upto4)
df
anova = aov(y~A+B+C, data=df)
summary(anova)
anova = aov(y~block+A+B+C, data=df)
summary(anova)
anova = aov(y~A+B+C-block, data=df)
summary(anova)
anova = aov(y~block+A+B+C, data=df)
summary(anova)
y = c(3.1,3.3,6.3,6.7,4.1,4.0,6.5,6.3)
A = c(0,1,0,1,0,1,0,1)
B = c(0,0,1,1,0,0,1,1)
C = c(0,0,0,0,1,1,1,1)
block = c(1,2,2,2,1,1,1,2)
df = data.frame(y, A, B, C, block)
df$A = factor(df$A, levels=c(0,1))
df$B = factor(df$B, levels=c(0,1))
df$C = factor(df$C, levels=c(0,1))
df$block = factor(df$block, levels=c(1,2))
upto4 = aov(y~(A+B+C)^3, data=df)
summary(upto4)
df
anova = aov(y~block+A+B+C, data=df)
summary(anova)
upto4 = aov(y~(A+B+C)^3, data=df)
summary(upto4)
anova = aov(y~block+A+B+C, data=df)
summary(anova)
anova = aov(y~A+B+C, data=df)
anova = aov(y~A+B+C, data=df)
summary(anova)
0.011+0.011+15.961+0.281+0.553
0.553+0.011
0.554/3
